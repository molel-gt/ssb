# slurm.conf file generated by configurator.html.
# Put this file on all nodes of your cluster.
# See the slurm.conf man page for more information.
#
ClusterName=localcluster
SlurmctldHost=localhost
MpiDefault=none
ProctrackType=proctrack/cgroup
ReturnToService=2
SlurmctldPidFile=/var/run/slurmctld.pid
SlurmctldPort=6817
SlurmdPidFile=/var/run/slurmd.pid
SlurmdPort=6818
SlurmdSpoolDir=/var/lib/slurm/slurmd
SlurmUser=slurm
StateSaveLocation=/var/lib/slurm/slurmctld
SwitchType=switch/none
TaskPlugin=task/cgroup,task/affinity
#
# TIMERS
InactiveLimit=0
KillWait=30
MinJobAge=300
SlurmctldTimeout=120
SlurmdTimeout=300
Waittime=0
# SCHEDULING
SchedulerType=sched/backfill
SelectType=select/cons_tres
SelectTypeParameters=CR_CPU_Memory,CR_LLN,CR_Core_Memory
PreemptType=preempt/partition_prio
PreemptMode=SUSPEND,GANG
PriorityType=priority/multifactor
PriorityWeightFairshare=10000
PriorityWeightAge=10000
PriorityWeightJobSize=10000
PriorityFavorSmall=YES
PriorityWeightQOS=10000
#
#AccountingStoragePort=
AccountingStorageType=accounting_storage/slurmdbd
AccountingStorageEnforce=associations
JobCompType=jobcomp/none
JobAcctGatherFrequency=30
JobAcctGatherType=jobacct_gather/cgroup
SlurmctldDebug=info
SlurmctldLogFile=/var/log/slurm/slurmctld.log
SlurmdDebug=info
SlurmdLogFile=/var/log/slurm/slurmd.log
#
# COMPUTE NODES
NodeName=localhost CPUs=16 RealMemory=60000 State=UNKNOWN Gres=gpu ThreadsPerCore=2 MemSpecLimit=4096
PartitionName=High PriorityTier=1 OverSubscribe=FORCE:1 Nodes=ALL Default=YES MaxTime=INFINITE State=UP DefMemPerNode=1000 MaxMemPerNode=1000
PartitionName=Normal PriorityTier=2 OverSubscribe=FORCE:1 Nodes=ALL Default=YES MaxTime=INFINITE State=UP DefMemPerNode=1000 MaxMemPerNode=1000
PartitionName=Low PriorityTier=3 OverSubscribe=FORCE:1 Nodes=ALL Default=NO MaxTime=INFINITE State=UP DefMemPerNode=1000 MaxMemPerNode=1000
